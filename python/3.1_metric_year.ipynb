{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from girth import twopl_mml\n",
    "from scipy.stats import entropy\n",
    "from constants import SAVE_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load region-product data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade = pd.read_parquet(\n",
    "    f\"{SAVE_FOLDER}/cleaned.parquet\",\n",
    "    columns=[\n",
    "        \"year\",\n",
    "        \"region\",\n",
    "        \"prod\",\n",
    "        \"export\",\n",
    "        \"regionsum\",\n",
    "        \"prodsum\",\n",
    "        \"yearsum\",\n",
    "        \"rca\",\n",
    "        \"binrca\",\n",
    "    ],\n",
    ")\n",
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform RCA with R0 and generate different projections\n",
    "R0 = 0.115\n",
    "trade[\"llrca\"] = np.log(1 + trade.rca / R0) / np.log(1 + 1 / R0)\n",
    "trade.columns, trade.shape, trade[[\"year\", \"region\", \"prod\"]].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate 1962-based metrics of ECI/ECI-star/fitness\n",
    "mcpdf = (\n",
    "    trade[trade.year == 1962]\n",
    "    .pivot(index=\"region\", columns=\"prod\", values=\"binrca\")\n",
    "    .fillna(0)\n",
    ")\n",
    "rcadf = (\n",
    "    trade[trade.year == 1962]\n",
    "    .pivot(index=\"region\", columns=\"prod\", values=\"rca\")\n",
    "    .fillna(0)\n",
    ")\n",
    "mcp = mcpdf.values\n",
    "rcamat = rcadf.values\n",
    "diversity = mcp.sum(axis=1)\n",
    "mcp = mcp[diversity > 0, :]\n",
    "rcamat = rcamat[diversity > 0, :]\n",
    "ubiquity = mcp.sum(axis=0)\n",
    "diversity = mcp.sum(axis=1)\n",
    "\n",
    "\n",
    "## calculate normalized proximity phi-M (A1), phi-P (A2), phi-C (A3) for 1962\n",
    "A = mcp.T @ mcp\n",
    "A = A / ubiquity[np.newaxis, :]\n",
    "A = np.minimum(A, A.T)\n",
    "np.fill_diagonal(A, 0)\n",
    "den = A.sum(axis=0)\n",
    "A1 = np.diag(1 / den) @ A\n",
    "A2 = np.diag(1 / ubiquity) @ mcp.T @ np.diag(1 / diversity) @ mcp\n",
    "A3 = (1 + np.corrcoef(rcamat.T)) / 2\n",
    "den = A3.sum(axis=0)\n",
    "A3 = np.diag(1 / den) @ A3\n",
    "eigvals1, eigvecs1 = np.linalg.eig(A1)\n",
    "eigvecs1 = np.real(eigvecs1)\n",
    "assert np.array_equal(np.argsort(-eigvals1)[:2], np.array([0, 1]))\n",
    "eigvals1_l, eigvecs1_l = np.linalg.eig(A1.T)\n",
    "eigvecs1_l = np.real(eigvecs1_l)\n",
    "assert np.array_equal(np.argsort(-eigvals1_l)[:2], np.array([0, 1]))\n",
    "eigvals2, eigvecs2 = np.linalg.eig(A2)\n",
    "eigvecs2 = np.real(eigvecs2)\n",
    "assert np.array_equal(np.argsort(-eigvals2)[:2], np.array([0, 1]))\n",
    "eigvals2_l, eigvecs2_l = np.linalg.eig(A2.T)\n",
    "eigvecs2_l = np.real(eigvecs2_l)\n",
    "assert np.array_equal(np.argsort(-eigvals2_l)[:2], np.array([0, 1]))\n",
    "eigvals3, eigvecs3 = np.linalg.eig(A3)\n",
    "eigvecs3 = np.real(eigvecs3)\n",
    "assert np.array_equal(np.argsort(-eigvals3)[:2], np.array([0, 1]))\n",
    "eigvals3_l, eigvecs3_l = np.linalg.eig(A3.T)\n",
    "eigvecs3_l = np.real(eigvecs3_l)\n",
    "assert np.array_equal(np.argsort(-eigvals3_l)[:2], np.array([0, 1]))\n",
    "\n",
    "pivec1 = eigvecs1_l[:, 0]\n",
    "pivec2 = eigvecs2_l[:, 0]\n",
    "pivec3 = eigvecs3_l[:, 0]\n",
    "pivec1_1962 = pivec1 / pivec1.sum()\n",
    "pivec2_1962 = pivec2 / pivec2.sum()\n",
    "pivec3_1962 = pivec3 / pivec3.sum()\n",
    "\n",
    "diversity = mcp.sum(axis=1)\n",
    "pci_p = (\n",
    "    np.sign(np.real(np.corrcoef(diversity, mcp @ eigvecs2[:, 1])[0, 1]))\n",
    "    * eigvecs2[:, 1]\n",
    ")\n",
    "pci_m = (\n",
    "    np.sign(np.real(np.corrcoef(eigvecs1[:, 1], eigvecs2[:, 1])[0, 1])) * eigvecs1[:, 1]\n",
    ")\n",
    "pci_c = (\n",
    "    np.sign(np.real(np.corrcoef(eigvecs3[:, 1], eigvecs2[:, 1])[0, 1])) * eigvecs3[:, 1]\n",
    ")\n",
    "pcil_p = np.sign(eigvecs2_l[:, 1].dot(pci_p)) * eigvecs2_l[:, 1]\n",
    "pcil_m = np.sign(eigvecs1_l[:, 1].dot(pci_m)) * eigvecs1_l[:, 1]\n",
    "pcil_c = np.sign(eigvecs3_l[:, 1].dot(pci_c)) * eigvecs3_l[:, 1]\n",
    "\n",
    "pci_1962 = pci_p.copy()\n",
    "pci_m_1962 = pci_m * 1 / np.sqrt(pci_m.T @ np.diag(pivec1_1962) @ pci_m)\n",
    "pci_p_1962 = pci_p * 1 / np.sqrt(pci_p.T @ np.diag(pivec2_1962) @ pci_p)\n",
    "pci_c_1962 = pci_c * 1 / np.sqrt(pci_c.T @ np.diag(pivec3_1962) @ pci_c)\n",
    "pcil_m_1962 = pcil_m * 1 / np.sqrt(pcil_m.T @ np.diag(1 / pivec1_1962) @ pcil_m)\n",
    "pcil_p_1962 = pcil_p * 1 / np.sqrt(pcil_p.T @ np.diag(1 / pivec2_1962) @ pcil_p)\n",
    "pcil_c_1962 = pcil_c * 1 / np.sqrt(pcil_c.T @ np.diag(1 / pivec3_1962) @ pcil_c)\n",
    "\n",
    "##fitness_1962\n",
    "qp = np.ones(mcp.shape[1])\n",
    "fc = np.ones(mcp.shape[0])\n",
    "for i in range(19):\n",
    "    fc_t = mcp @ qp\n",
    "    qp_t = 1 / (mcp.T @ (1 / fc))\n",
    "    fc = fc_t / fc_t.mean()\n",
    "    qp = qp_t / qp_t.mean()\n",
    "\n",
    "qp_1962 = qp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processyear(year):\n",
    "    ### calculate yearly country complexity metric\n",
    "    df = trade[trade.year == year].copy()\n",
    "    df[\"diversity\"] = df.groupby(\"region\")[\"binrca\"].transform(\"sum\")\n",
    "    # ECI/ECI_Star for 1962 and yearly rolling version, see annotation in other notebooks\n",
    "    mcpdf = df.pivot(index=\"region\", columns=\"prod\", values=\"binrca\").fillna(0)\n",
    "    rcadf = df.pivot(index=\"region\", columns=\"prod\", values=\"rca\").fillna(0)\n",
    "    mcp = mcpdf.values\n",
    "    rcamat = rcadf.values\n",
    "    ubiquity = mcp.sum(axis=0)\n",
    "    diversity = mcp.sum(axis=1)\n",
    "    if ubiquity.min() == 0:\n",
    "        print(f\"error {year}! mcp mat ubi=0\")\n",
    "    mcp = mcp[diversity > 0, :]\n",
    "    ubiquity = rcamat.sum(axis=0)\n",
    "    diversity = rcamat.sum(axis=1)\n",
    "    if ubiquity.min() == 0:\n",
    "        print(f\"error {year}! rca mat ubi=0\")\n",
    "    rcamat = rcamat[diversity > 0, :]\n",
    "    ubiquity = mcp.sum(axis=0)\n",
    "    diversity = mcp.sum(axis=1)\n",
    "    A = mcp.T @ mcp\n",
    "    A = A / ubiquity[np.newaxis, :]\n",
    "    A = np.minimum(A, A.T)\n",
    "    np.fill_diagonal(A, 0)\n",
    "    den = A.sum(axis=0)\n",
    "    A1 = np.diag(1 / den) @ A\n",
    "    A2 = np.diag(1 / ubiquity) @ mcp.T @ np.diag(1 / diversity) @ mcp\n",
    "    A3 = (1 + np.corrcoef(rcamat.T)) / 2\n",
    "    den = A3.sum(axis=0)\n",
    "    A3 = np.diag(1 / den) @ A3\n",
    "\n",
    "    eigvals1, eigvecs1 = np.linalg.eig(A1)\n",
    "    eigvecs1 = np.real(eigvecs1)\n",
    "    assert np.array_equal(np.argsort(-eigvals1)[:2], np.array([0, 1]))\n",
    "    eigvals1_l, eigvecs1_l = np.linalg.eig(A1.T)\n",
    "    eigvecs1_l = np.real(eigvecs1_l)\n",
    "    assert np.array_equal(np.argsort(-eigvals1_l)[:2], np.array([0, 1]))\n",
    "    eigvals2, eigvecs2 = np.linalg.eig(A2)\n",
    "    eigvecs2 = np.real(eigvecs2)\n",
    "    assert np.array_equal(np.argsort(-eigvals2)[:2], np.array([0, 1]))\n",
    "    eigvals2_l, eigvecs2_l = np.linalg.eig(A2.T)\n",
    "    eigvecs2_l = np.real(eigvecs2_l)\n",
    "    assert np.array_equal(np.argsort(-eigvals2_l)[:2], np.array([0, 1]))\n",
    "    eigvals3, eigvecs3 = np.linalg.eig(A3)\n",
    "    eigvecs3 = np.real(eigvecs3)\n",
    "    assert np.array_equal(np.argsort(-eigvals3)[:2], np.array([0, 1]))\n",
    "    eigvals3_l, eigvecs3_l = np.linalg.eig(A3.T)\n",
    "    eigvecs3_l = np.real(eigvecs3_l)\n",
    "    assert np.array_equal(np.argsort(-eigvals3_l)[:2], np.array([0, 1]))\n",
    "\n",
    "    pivec1 = eigvecs1_l[:, 0]\n",
    "    pivec2 = eigvecs2_l[:, 0]\n",
    "    pivec3 = eigvecs3_l[:, 0]\n",
    "    pivec1 = pivec1 / pivec1.sum()\n",
    "    pivec2 = pivec2 / pivec2.sum()\n",
    "    pivec3 = pivec3 / pivec3.sum()\n",
    "\n",
    "    diversity = mcp.sum(axis=1)\n",
    "    pci_p = (\n",
    "        np.sign(np.real(np.corrcoef(diversity, mcp @ eigvecs2[:, 1])[0, 1]))\n",
    "        * eigvecs2[:, 1]\n",
    "    )\n",
    "\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pci_p, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pci\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pci_1962, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pci_1962\"})\n",
    "    )\n",
    "\n",
    "    pci_m = (\n",
    "        np.sign(np.real(np.corrcoef(eigvecs1[:, 1], eigvecs2[:, 1])[0, 1]))\n",
    "        * eigvecs1[:, 1]\n",
    "    )\n",
    "    pci_c = (\n",
    "        np.sign(np.real(np.corrcoef(eigvecs3[:, 1], eigvecs2[:, 1])[0, 1]))\n",
    "        * eigvecs3[:, 1]\n",
    "    )\n",
    "    pcil_p = np.sign(eigvecs2_l[:, 1].dot(pci_p)) * eigvecs2_l[:, 1]\n",
    "    pcil_m = np.sign(eigvecs1_l[:, 1].dot(pci_m)) * eigvecs1_l[:, 1]\n",
    "    pcil_c = np.sign(eigvecs3_l[:, 1].dot(pci_c)) * eigvecs3_l[:, 1]\n",
    "\n",
    "    pci_m = pci_m * 1 / np.sqrt(pci_m.T @ np.diag(pivec1) @ pci_m)\n",
    "    pci_p = pci_p * 1 / np.sqrt(pci_p.T @ np.diag(pivec2) @ pci_p)\n",
    "    pci_c = pci_c * 1 / np.sqrt(pci_c.T @ np.diag(pivec3) @ pci_c)\n",
    "    pcil_m = pcil_m * 1 / np.sqrt(pcil_m.T @ np.diag(1 / pivec1) @ pcil_m)\n",
    "    pcil_p = pcil_p * 1 / np.sqrt(pcil_p.T @ np.diag(1 / pivec2) @ pcil_p)\n",
    "    pcil_c = pcil_c * 1 / np.sqrt(pcil_c.T @ np.diag(1 / pivec3) @ pcil_c)\n",
    "\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pivec2, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pivec_p\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pivec1, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pivec_m\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pivec3, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pivec_c\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pci_p, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pci_p\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pci_m, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pci_m\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pci_c, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pci_c\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pcil_p, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pcil_p\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pcil_m, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pcil_m\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pcil_c, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pcil_c\"})\n",
    "    )\n",
    "\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pivec2_1962, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pivec_p_1962\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pivec1_1962, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pivec_m_1962\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pivec3_1962, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pivec_c_1962\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pci_p_1962, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pci_p_1962\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pci_m_1962, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pci_m_1962\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pci_c_1962, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pci_c_1962\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pcil_p_1962, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pcil_p_1962\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pcil_m_1962, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pcil_m_1962\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(pcil_c_1962, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"pcil_c_1962\"})\n",
    "    )\n",
    "    df = df.merge(\n",
    "        pd.DataFrame(qp_1962, index=mcpdf.columns)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"qp_1962\"})\n",
    "    )\n",
    "\n",
    "    df[\"avgrca_part_p\"] = df.llrca * df.pivec_p\n",
    "    df[\"avgrca_part_m\"] = df.llrca * df.pivec_m\n",
    "    df[\"avgrca_part_c\"] = df.llrca * df.pivec_c\n",
    "    df[\"avgrca_p\"] = df.groupby([\"year\", \"region\"])[\"avgrca_part_p\"].transform(\"sum\")\n",
    "    df[\"avgrca_m\"] = df.groupby([\"year\", \"region\"])[\"avgrca_part_m\"].transform(\"sum\")\n",
    "    df[\"avgrca_c\"] = df.groupby([\"year\", \"region\"])[\"avgrca_part_c\"].transform(\"sum\")\n",
    "    df[\"eci_part\"] = np.where(df.diversity > 0, df.pci * df.binrca / df.diversity, 0)\n",
    "\n",
    "    df[\"avgrca_part_p_1962\"] = df.llrca * df.pivec_p_1962\n",
    "    df[\"avgrca_part_m_1962\"] = df.llrca * df.pivec_m_1962\n",
    "    df[\"avgrca_part_c_1962\"] = df.llrca * df.pivec_c_1962\n",
    "    df[\"avgrca_p_1962\"] = df.groupby([\"year\", \"region\"])[\n",
    "        \"avgrca_part_p_1962\"\n",
    "    ].transform(\"sum\")\n",
    "    df[\"avgrca_m_1962\"] = df.groupby([\"year\", \"region\"])[\n",
    "        \"avgrca_part_m_1962\"\n",
    "    ].transform(\"sum\")\n",
    "    df[\"avgrca_c_1962\"] = df.groupby([\"year\", \"region\"])[\n",
    "        \"avgrca_part_c_1962\"\n",
    "    ].transform(\"sum\")\n",
    "    df[\"eci_part_1962\"] = np.where(\n",
    "        df.diversity > 0, df.pci_1962 * df.binrca / df.diversity, 0\n",
    "    )\n",
    "\n",
    "    df[\"rct_p\"] = np.where(df.avgrca_p > 0, df.llrca / df.avgrca_p, 0)\n",
    "    df[\"rct_m\"] = np.where(df.avgrca_m > 0, df.llrca / df.avgrca_m, 0)\n",
    "    df[\"rct_c\"] = np.where(df.avgrca_c > 0, df.llrca / df.avgrca_c, 0)\n",
    "    df[\"rct_demean_p\"] = df.rct_p - df.groupby(\"prod\").rct_p.transform(\"mean\")\n",
    "    df[\"rct_demean_m\"] = df.rct_m - df.groupby(\"prod\").rct_m.transform(\"mean\")\n",
    "    df[\"rct_demean_c\"] = df.rct_c - df.groupby(\"prod\").rct_c.transform(\"mean\")\n",
    "    df[\"proj_p\"] = np.where(\n",
    "        df.avgrca_p > 0, df.pci_p * df.llrca * df.pivec_p / df.avgrca_p, 0\n",
    "    )\n",
    "    df[\"proj_m\"] = np.where(\n",
    "        df.avgrca_m > 0, df.pci_m * df.llrca * df.pivec_m / df.avgrca_m, 0\n",
    "    )\n",
    "    df[\"proj_c\"] = np.where(\n",
    "        df.avgrca_c > 0, df.pci_c * df.llrca * df.pivec_c / df.avgrca_c, 0\n",
    "    )\n",
    "\n",
    "    df[\"rct_p_1962\"] = np.where(df.avgrca_p_1962 > 0, df.llrca / df.avgrca_p_1962, 0)\n",
    "    df[\"rct_m_1962\"] = np.where(df.avgrca_m_1962 > 0, df.llrca / df.avgrca_m_1962, 0)\n",
    "    df[\"rct_c_1962\"] = np.where(df.avgrca_c_1962 > 0, df.llrca / df.avgrca_c_1962, 0)\n",
    "    df[\"rct_demean_p_1962\"] = df.rct_p_1962 - df.groupby(\"prod\").rct_p_1962.transform(\n",
    "        \"mean\"\n",
    "    )\n",
    "    df[\"rct_demean_m_1962\"] = df.rct_m_1962 - df.groupby(\"prod\").rct_m_1962.transform(\n",
    "        \"mean\"\n",
    "    )\n",
    "    df[\"rct_demean_c_1962\"] = df.rct_c_1962 - df.groupby(\"prod\").rct_c_1962.transform(\n",
    "        \"mean\"\n",
    "    )\n",
    "    df[\"proj_p_1962\"] = np.where(\n",
    "        df.avgrca_p_1962 > 0,\n",
    "        df.pci_p_1962 * df.llrca * df.pivec_p_1962 / df.avgrca_p_1962,\n",
    "        0,\n",
    "    )\n",
    "    df[\"proj_m_1962\"] = np.where(\n",
    "        df.avgrca_m_1962 > 0,\n",
    "        df.pci_m_1962 * df.llrca * df.pivec_m_1962 / df.avgrca_m_1962,\n",
    "        0,\n",
    "    )\n",
    "    df[\"proj_c_1962\"] = np.where(\n",
    "        df.avgrca_c_1962 > 0,\n",
    "        df.pci_c_1962 * df.llrca * df.pivec_c_1962 / df.avgrca_c_1962,\n",
    "        0,\n",
    "    )\n",
    "\n",
    "    ## fitness 1962 version\n",
    "    df[\"fitness_1962\"] = np.where(df.diversity > 0, df.qp_1962 * df.binrca, 0)\n",
    "    df[\"fitness_1962\"] = df[\"fitness_1962\"] / (df[\"fitness_1962\"].sum() / mcp.shape[0])\n",
    "\n",
    "    ## fitness-yearly version\n",
    "    qp = np.ones(mcp.shape[1])\n",
    "    fc = np.ones(mcp.shape[0])\n",
    "    for i in range(20):\n",
    "        fc_t = mcp @ qp\n",
    "        qp_t = 1 / (mcp.T @ (1 / fc))\n",
    "        fc = fc_t / fc_t.mean()\n",
    "        qp = qp_t / qp_t.mean()\n",
    "\n",
    "    ## genepy\n",
    "    kc = mcp.sum(axis=1)\n",
    "    kp_1 = (np.diag(1 / kc) @ mcp).sum(axis=0)\n",
    "    wcp = np.diag(1 / kc) @ mcp @ np.diag(1 / kp_1)\n",
    "    ncc = wcp @ wcp.T\n",
    "    np.fill_diagonal(ncc, 0)\n",
    "    eigvals, eigvecs = np.linalg.eigh(ncc)\n",
    "    xc1 = np.absolute(eigvecs[:, -1])\n",
    "    xc2 = eigvecs[:, -2]\n",
    "    lambda1 = np.real(eigvals[-1])\n",
    "    lambda2 = np.real(eigvals[-2])\n",
    "    genepy = np.square(lambda1 * np.square(xc1) + lambda2 * np.square(xc2)) + 2 * (\n",
    "        lambda1**2 * np.square(xc1) + lambda2**2 * np.square(xc2)\n",
    "    )\n",
    "\n",
    "    ## production ability\n",
    "    estimates = twopl_mml(mcp.T)\n",
    "\n",
    "    ## fixed effects\n",
    "    fedf = trade[(trade.year == year) & (trade.export > 0)][\n",
    "        [\"region\", \"prod\", \"export\", \"rca\", \"regionsum\", \"prodsum\"]\n",
    "    ].copy()\n",
    "    fedf[\"ycp\"] = -np.log(-np.log(fedf.rca / (fedf.rca + 1)))\n",
    "    fedf[\"regionshare\"] = fedf.export / fedf.regionsum\n",
    "    fedf[\"prodshare\"] = fedf.export / fedf.prodsum\n",
    "    res = smf.ols(formula=\"ycp ~ region+prod\", data=fedf).fit()\n",
    "    fecoefdf = pd.DataFrame({\"fe\": res.params[1:]}).reset_index()\n",
    "    fecoefdf[\"var\"] = fecoefdf[\"index\"].str[-4:-1]\n",
    "    gamma_c = (\n",
    "        fedf[[\"region\"]]\n",
    "        .drop_duplicates()\n",
    "        .merge(fecoefdf[[\"var\", \"fe\"]].rename(columns={\"var\": \"region\"}), how=\"left\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    ## entropy\n",
    "    tmpdf2 = fedf[[\"region\", \"prod\", \"export\"]].copy()\n",
    "    tmpdf2[\"hc\"] = tmpdf2.groupby(\"region\")[\"export\"].transform(entropy)\n",
    "    tmpdf2[\"hp\"] = tmpdf2.groupby(\"prod\")[\"export\"].transform(entropy)\n",
    "    tmpdf2[\"xcp\"] = tmpdf2.export * (np.log(233) - tmpdf2.hp)\n",
    "    tmpdf2[\"ycp\"] = tmpdf2.export * (np.log(235) - tmpdf2.hc)\n",
    "    tmpdf2[\"xcpr\"] = tmpdf2.xcp / tmpdf2.groupby(\"region\")[\"xcp\"].transform(\"sum\")\n",
    "    tmpdf2[\"ycpr\"] = tmpdf2.ycp / tmpdf2.groupby(\"prod\")[\"ycp\"].transform(\"sum\")\n",
    "    for i in range(25):\n",
    "        tmpdf2[\"hc\"] = tmpdf2.groupby(\"region\")[\"xcpr\"].transform(entropy)\n",
    "        tmpdf2[\"hp\"] = tmpdf2.groupby(\"prod\")[\"ycpr\"].transform(entropy)\n",
    "        tmpdf2[\"xcp\"] = tmpdf2.export * (np.log(233) - tmpdf2.hp)\n",
    "        tmpdf2[\"ycp\"] = tmpdf2.export * (np.log(235) - tmpdf2.hc)\n",
    "        tmpdf2[\"xcpr\"] = tmpdf2.xcp / tmpdf2.groupby(\"region\")[\"xcp\"].transform(\"sum\")\n",
    "        tmpdf2[\"ycpr\"] = tmpdf2.ycp / tmpdf2.groupby(\"prod\")[\"ycp\"].transform(\"sum\")\n",
    "    regiondf2 = tmpdf2[[\"region\", \"hc\"]].drop_duplicates().sort_values(\"region\")\n",
    "\n",
    "    ## collect result\n",
    "    resdf = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"fitness\": fc,\n",
    "                \"diversity\": kc,\n",
    "                \"xc1\": xc1,\n",
    "                \"xc2\": xc2,\n",
    "                \"genepy\": genepy,\n",
    "                \"ability\": estimates[\"Ability\"],\n",
    "            },\n",
    "            index=mcpdf.index[mcpdf.sum(axis=1) > 0],\n",
    "        )\n",
    "        .reset_index()\n",
    "        .merge(gamma_c)\n",
    "        .merge(regiondf2)\n",
    "        .merge(\n",
    "            df.groupby([\"year\", \"region\"])[\n",
    "                [\n",
    "                    \"avgrca_part_p\",\n",
    "                    \"avgrca_part_m\",\n",
    "                    \"avgrca_part_c\",\n",
    "                    \"proj_p\",\n",
    "                    \"proj_m\",\n",
    "                    \"proj_c\",\n",
    "                    \"eci_part\",\n",
    "                    \"avgrca_part_p_1962\",\n",
    "                    \"avgrca_part_m_1962\",\n",
    "                    \"avgrca_part_c_1962\",\n",
    "                    \"proj_p_1962\",\n",
    "                    \"proj_m_1962\",\n",
    "                    \"proj_c_1962\",\n",
    "                    \"eci_part_1962\",\n",
    "                    \"fitness_1962\",\n",
    "                ]\n",
    "            ]\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "            .rename(\n",
    "                columns={\n",
    "                    \"avgrca_part_p\": \"avgrca_p\",\n",
    "                    \"avgrca_part_m\": \"avgrca_m\",\n",
    "                    \"avgrca_part_c\": \"avgrca_c\",\n",
    "                    \"eci_part\": \"eci\",\n",
    "                    \"avgrca_part_p_1962\": \"avgrca_p_1962\",\n",
    "                    \"avgrca_part_m_1962\": \"avgrca_m_1962\",\n",
    "                    \"avgrca_part_c_1962\": \"avgrca_c_1962\",\n",
    "                    \"eci_part_1962\": \"eci_1962\",\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return resdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdict = dict()\n",
    "years = range(1962, 2019)\n",
    "for year in years:\n",
    "    print(f\"Processing year {year}...\")\n",
    "    try:\n",
    "        resdict[f\"year{year}\"] = processyear(year)\n",
    "    except:\n",
    "        print(f\"{year} has error!\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate and adjust signs of x2 and x2divsqrtd for comparision\n",
    "region_metricdf = pd.concat(\n",
    "    [resdict[f\"year{year}\"].assign(year=year) for year in years]\n",
    ")\n",
    "region_metricdf[\"x1d\"] = region_metricdf.xc1 * region_metricdf.diversity\n",
    "region_metricdf[\"x2divsqrtd\"] = region_metricdf.xc2 / np.sqrt(region_metricdf.diversity)\n",
    "signdf = np.sign(\n",
    "    region_metricdf.groupby(\"year\")[[\"x2divsqrtd\", \"eci\"]].corr().unstack().iloc[:, 1]\n",
    ").reset_index()\n",
    "signdf.columns = [\"year\", \"sign\"]\n",
    "region_metricdf = region_metricdf.merge(signdf, how=\"left\")\n",
    "region_metricdf[\"x2divsqrtd\"] = region_metricdf[\"x2divsqrtd\"] * region_metricdf[\"sign\"]\n",
    "region_metricdf[\"xc2\"] = region_metricdf[\"xc2\"] * region_metricdf[\"sign\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_metricdf.to_csv(f\"{SAVE_FOLDER}/region_year_metric.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_year_corr = (\n",
    "    region_metricdf.drop(columns=[\"region\"])\n",
    "    .groupby(\"year\")\n",
    "    .corr()\n",
    "    .stack()\n",
    "    .reset_index()\n",
    ")\n",
    "region_year_corr.columns = [\"year\", \"metric1\", \"metric2\", \"corrcoef\"]\n",
    "region_year_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_year_corr2 = (\n",
    "    region_metricdf.drop(columns=[\"region\"])\n",
    "    .groupby(\"year\")\n",
    "    .corr(method=\"spearman\")\n",
    "    .stack()\n",
    "    .reset_index()\n",
    ")\n",
    "region_year_corr2.columns = [\"year\", \"metric1\", \"metric2\", \"corrcoef\"]\n",
    "region_year_corr2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_year_corr.to_csv(f\"{SAVE_FOLDER}/region_year_corr.tsv\", sep=\"\\t\", index=False)\n",
    "region_year_corr2.to_csv(\n",
    "    f\"{SAVE_FOLDER}/region_year_rankcorr.tsv\", sep=\"\\t\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
